{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(256),\n",
    "    transforms.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_batch = []\n",
    "target_list = []\n",
    "train_data = []\n",
    "batchSize = 10\n",
    "\n",
    "files = listdir('images/train')\n",
    "for i in range(len(listdir('images/train'))):\n",
    "    f = random.choice(files)\n",
    "    files.remove(f)\n",
    "    img = Image.open(\"images/train/\" + f)\n",
    "\n",
    "    img_tensor = transform(img)\n",
    "    \n",
    "    \n",
    "    train_data_batch.append(img_tensor)\n",
    "    #cracks = 1 if 'cracks' in f else 0  -->>> errado\n",
    "    nocracks = 1 if 'nocracks' in f else 0\n",
    "    cracks = 1 - nocracks\n",
    "    \n",
    "    target = [cracks, nocracks]\n",
    "    target_list.append(target)\n",
    "\n",
    "    \n",
    "    if len(train_data_batch) >= batchSize: # 10 = tamanho do batch\n",
    "        train_data.append((train_data_batch, target_list))\n",
    "       \n",
    "        train_data_batch = []\n",
    "        target_list = []\n",
    "        \n",
    "       # print('Loaded batch', len(train_data_list), 'of', int(len('images/train'))/2)\n",
    "       # print('Percentage Done: ', len (train_data)/int(len(listdir('images/train'))/2), '%')\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=3, stride = 1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(6, 12, kernel_size=3, stride = 1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(12, 18, kernel_size=3, stride = 1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(18, 24, kernel_size=3, stride = 1, padding=1)\n",
    "        self.fc1 = nn.Linear(6144, 60) #in and out dataset\n",
    "        self.fc2 = nn.Linear(60, 2) ##### 10 --> 2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x =F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = self.conv4(x)\n",
    "        x =F.max_pool2d(x, 2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "       \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.train()\n",
    "#model.cuda()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "def train(epoch):\n",
    "    \n",
    "    batch_id = 0\n",
    "    correct=0\n",
    "    for data, target in train_data:\n",
    "        #data = data.cuda()\n",
    "        data = pad_sequence(data, batch_first=True)\n",
    "        \n",
    "        target = torch.Tensor(target) #.cuda()\n",
    "        \n",
    "        #print(\"T=\",target.shape)\n",
    "        data = Variable(data)\n",
    "        target = Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        \n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        _, t = torch.max(target, 1)\n",
    "        \n",
    "        correct += (predicted.cpu() == t.cpu()).sum().numpy()\n",
    "        \n",
    "        \n",
    "        criterion = F.binary_cross_entropy\n",
    "       \n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_id = batch_id + 1\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)] \\tLoss; {:.6f}; \\tacurracy {:.2f}'.format(epoch, batch_id * len(data), len(train_data)*len(data), 100. * batch_id / len(train_data), loss.item(), correct/(batch_id*len(data))))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [10/40 (25%)] \tLoss; 0.682940; \tacurracy 0.70\n",
      "Train Epoch: 1 [20/40 (50%)] \tLoss; 2.210621; \tacurracy 0.55\n",
      "Train Epoch: 1 [30/40 (75%)] \tLoss; 0.679486; \tacurracy 0.57\n",
      "Train Epoch: 1 [40/40 (100%)] \tLoss; 0.655552; \tacurracy 0.60\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 2 [10/40 (25%)] \tLoss; 0.768606; \tacurracy 0.30\n",
      "Train Epoch: 2 [20/40 (50%)] \tLoss; 0.677431; \tacurracy 0.45\n",
      "Train Epoch: 2 [30/40 (75%)] \tLoss; 0.712428; \tacurracy 0.43\n",
      "Train Epoch: 2 [40/40 (100%)] \tLoss; 0.684728; \tacurracy 0.50\n",
      "tensor([[ 0]])\n",
      "Train Epoch: 3 [10/40 (25%)] \tLoss; 0.694451; \tacurracy 0.40\n",
      "Train Epoch: 3 [20/40 (50%)] \tLoss; 0.690723; \tacurracy 0.40\n",
      "Train Epoch: 3 [30/40 (75%)] \tLoss; 0.660670; \tacurracy 0.47\n",
      "Train Epoch: 3 [40/40 (100%)] \tLoss; 0.724251; \tacurracy 0.42\n",
      "tensor([[ 0]])\n",
      "Train Epoch: 4 [10/40 (25%)] \tLoss; 0.620487; \tacurracy 0.70\n",
      "Train Epoch: 4 [20/40 (50%)] \tLoss; 0.638109; \tacurracy 0.55\n",
      "Train Epoch: 4 [30/40 (75%)] \tLoss; 0.501356; \tacurracy 0.63\n",
      "Train Epoch: 4 [40/40 (100%)] \tLoss; 0.594188; \tacurracy 0.55\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 5 [10/40 (25%)] \tLoss; 0.475854; \tacurracy 0.80\n",
      "Train Epoch: 5 [20/40 (50%)] \tLoss; 0.495584; \tacurracy 0.70\n",
      "Train Epoch: 5 [30/40 (75%)] \tLoss; 0.391619; \tacurracy 0.70\n",
      "Train Epoch: 5 [40/40 (100%)] \tLoss; 0.278755; \tacurracy 0.72\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 6 [10/40 (25%)] \tLoss; 0.394719; \tacurracy 0.70\n",
      "Train Epoch: 6 [20/40 (50%)] \tLoss; 0.304181; \tacurracy 0.85\n",
      "Train Epoch: 6 [30/40 (75%)] \tLoss; 0.223410; \tacurracy 0.87\n",
      "Train Epoch: 6 [40/40 (100%)] \tLoss; 1.188216; \tacurracy 0.85\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 7 [10/40 (25%)] \tLoss; 0.334990; \tacurracy 0.70\n",
      "Train Epoch: 7 [20/40 (50%)] \tLoss; 0.241648; \tacurracy 0.85\n",
      "Train Epoch: 7 [30/40 (75%)] \tLoss; 0.176598; \tacurracy 0.87\n",
      "Train Epoch: 7 [40/40 (100%)] \tLoss; 0.177623; \tacurracy 0.90\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 8 [10/40 (25%)] \tLoss; 0.406240; \tacurracy 0.70\n",
      "Train Epoch: 8 [20/40 (50%)] \tLoss; 0.328530; \tacurracy 0.85\n",
      "Train Epoch: 8 [30/40 (75%)] \tLoss; 0.224328; \tacurracy 0.87\n",
      "Train Epoch: 8 [40/40 (100%)] \tLoss; 0.214544; \tacurracy 0.90\n",
      "tensor([[ 0]])\n",
      "Train Epoch: 9 [10/40 (25%)] \tLoss; 0.382721; \tacurracy 0.70\n",
      "Train Epoch: 9 [20/40 (50%)] \tLoss; 0.187308; \tacurracy 0.85\n",
      "Train Epoch: 9 [30/40 (75%)] \tLoss; 0.181489; \tacurracy 0.87\n",
      "Train Epoch: 9 [40/40 (100%)] \tLoss; 0.092332; \tacurracy 0.90\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 10 [10/40 (25%)] \tLoss; 0.479679; \tacurracy 0.70\n",
      "Train Epoch: 10 [20/40 (50%)] \tLoss; 0.092376; \tacurracy 0.85\n",
      "Train Epoch: 10 [30/40 (75%)] \tLoss; 0.181646; \tacurracy 0.87\n",
      "Train Epoch: 10 [40/40 (100%)] \tLoss; 0.085377; \tacurracy 0.90\n",
      "tensor([[ 0]])\n",
      "Train Epoch: 11 [10/40 (25%)] \tLoss; 0.451837; \tacurracy 0.70\n",
      "Train Epoch: 11 [20/40 (50%)] \tLoss; 0.667868; \tacurracy 0.80\n",
      "Train Epoch: 11 [30/40 (75%)] \tLoss; 0.168723; \tacurracy 0.83\n",
      "Train Epoch: 11 [40/40 (100%)] \tLoss; 0.092404; \tacurracy 0.88\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 12 [10/40 (25%)] \tLoss; 0.455526; \tacurracy 0.70\n",
      "Train Epoch: 12 [20/40 (50%)] \tLoss; 0.165645; \tacurracy 0.85\n",
      "Train Epoch: 12 [30/40 (75%)] \tLoss; 0.394873; \tacurracy 0.83\n",
      "Train Epoch: 12 [40/40 (100%)] \tLoss; 1.067202; \tacurracy 0.85\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 13 [10/40 (25%)] \tLoss; 0.483484; \tacurracy 0.70\n",
      "Train Epoch: 13 [20/40 (50%)] \tLoss; 0.283587; \tacurracy 0.80\n",
      "Train Epoch: 13 [30/40 (75%)] \tLoss; 0.408085; \tacurracy 0.80\n",
      "Train Epoch: 13 [40/40 (100%)] \tLoss; 0.130462; \tacurracy 0.85\n",
      "tensor([[ 0]])\n",
      "Train Epoch: 14 [10/40 (25%)] \tLoss; 0.905922; \tacurracy 0.50\n",
      "Train Epoch: 14 [20/40 (50%)] \tLoss; 0.579560; \tacurracy 0.60\n",
      "Train Epoch: 14 [30/40 (75%)] \tLoss; 0.492516; \tacurracy 0.63\n",
      "Train Epoch: 14 [40/40 (100%)] \tLoss; 0.217746; \tacurracy 0.72\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 15 [10/40 (25%)] \tLoss; 0.596528; \tacurracy 0.60\n",
      "Train Epoch: 15 [20/40 (50%)] \tLoss; 0.354872; \tacurracy 0.75\n",
      "Train Epoch: 15 [30/40 (75%)] \tLoss; 0.375774; \tacurracy 0.77\n",
      "Train Epoch: 15 [40/40 (100%)] \tLoss; 0.188095; \tacurracy 0.82\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 16 [10/40 (25%)] \tLoss; 0.418022; \tacurracy 0.70\n",
      "Train Epoch: 16 [20/40 (50%)] \tLoss; 0.218982; \tacurracy 0.85\n",
      "Train Epoch: 16 [30/40 (75%)] \tLoss; 0.274187; \tacurracy 0.87\n",
      "Train Epoch: 16 [40/40 (100%)] \tLoss; 0.155104; \tacurracy 0.90\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 17 [10/40 (25%)] \tLoss; 0.347995; \tacurracy 0.70\n",
      "Train Epoch: 17 [20/40 (50%)] \tLoss; 0.152697; \tacurracy 0.85\n",
      "Train Epoch: 17 [30/40 (75%)] \tLoss; 0.292855; \tacurracy 0.87\n",
      "Train Epoch: 17 [40/40 (100%)] \tLoss; 0.100734; \tacurracy 0.90\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 18 [10/40 (25%)] \tLoss; 0.393321; \tacurracy 0.70\n",
      "Train Epoch: 18 [20/40 (50%)] \tLoss; 0.089142; \tacurracy 0.85\n",
      "Train Epoch: 18 [30/40 (75%)] \tLoss; 0.194776; \tacurracy 0.87\n",
      "Train Epoch: 18 [40/40 (100%)] \tLoss; 0.079252; \tacurracy 0.90\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 19 [10/40 (25%)] \tLoss; 0.361370; \tacurracy 0.70\n",
      "Train Epoch: 19 [20/40 (50%)] \tLoss; 0.108806; \tacurracy 0.85\n",
      "Train Epoch: 19 [30/40 (75%)] \tLoss; 0.122723; \tacurracy 0.87\n",
      "Train Epoch: 19 [40/40 (100%)] \tLoss; 0.110984; \tacurracy 0.90\n",
      "tensor([[ 0]])\n",
      "Train Epoch: 20 [10/40 (25%)] \tLoss; 0.229506; \tacurracy 0.80\n",
      "Train Epoch: 20 [20/40 (50%)] \tLoss; 0.133088; \tacurracy 0.90\n",
      "Train Epoch: 20 [30/40 (75%)] \tLoss; 0.028934; \tacurracy 0.93\n",
      "Train Epoch: 20 [40/40 (100%)] \tLoss; 0.075189; \tacurracy 0.95\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 21 [10/40 (25%)] \tLoss; 0.212200; \tacurracy 0.90\n",
      "Train Epoch: 21 [20/40 (50%)] \tLoss; 0.085604; \tacurracy 0.95\n",
      "Train Epoch: 21 [30/40 (75%)] \tLoss; 0.212261; \tacurracy 0.93\n",
      "Train Epoch: 21 [40/40 (100%)] \tLoss; 0.024879; \tacurracy 0.95\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 22 [10/40 (25%)] \tLoss; 0.213727; \tacurracy 0.90\n",
      "Train Epoch: 22 [20/40 (50%)] \tLoss; 0.040743; \tacurracy 0.95\n",
      "Train Epoch: 22 [30/40 (75%)] \tLoss; 0.051736; \tacurracy 0.97\n",
      "Train Epoch: 22 [40/40 (100%)] \tLoss; 0.033826; \tacurracy 0.97\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 23 [10/40 (25%)] \tLoss; 0.245332; \tacurracy 0.90\n",
      "Train Epoch: 23 [20/40 (50%)] \tLoss; 0.056187; \tacurracy 0.95\n",
      "Train Epoch: 23 [30/40 (75%)] \tLoss; 0.014138; \tacurracy 0.97\n",
      "Train Epoch: 23 [40/40 (100%)] \tLoss; 0.047997; \tacurracy 0.97\n",
      "tensor([[ 0]])\n",
      "Train Epoch: 24 [10/40 (25%)] \tLoss; 0.174453; \tacurracy 0.90\n",
      "Train Epoch: 24 [20/40 (50%)] \tLoss; 0.066790; \tacurracy 0.95\n",
      "Train Epoch: 24 [30/40 (75%)] \tLoss; 0.000963; \tacurracy 0.97\n",
      "Train Epoch: 24 [40/40 (100%)] \tLoss; 0.047341; \tacurracy 0.97\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 25 [10/40 (25%)] \tLoss; 0.141191; \tacurracy 0.90\n",
      "Train Epoch: 25 [20/40 (50%)] \tLoss; 0.059378; \tacurracy 0.95\n",
      "Train Epoch: 25 [30/40 (75%)] \tLoss; 0.000232; \tacurracy 0.97\n",
      "Train Epoch: 25 [40/40 (100%)] \tLoss; 0.025339; \tacurracy 0.97\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 26 [10/40 (25%)] \tLoss; 0.119139; \tacurracy 0.90\n",
      "Train Epoch: 26 [20/40 (50%)] \tLoss; 0.040672; \tacurracy 0.95\n",
      "Train Epoch: 26 [30/40 (75%)] \tLoss; 0.000092; \tacurracy 0.97\n",
      "Train Epoch: 26 [40/40 (100%)] \tLoss; 0.014779; \tacurracy 0.97\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 27 [10/40 (25%)] \tLoss; 0.122331; \tacurracy 0.90\n",
      "Train Epoch: 27 [20/40 (50%)] \tLoss; 0.029094; \tacurracy 0.95\n",
      "Train Epoch: 27 [30/40 (75%)] \tLoss; 0.000161; \tacurracy 0.97\n",
      "Train Epoch: 27 [40/40 (100%)] \tLoss; 0.008867; \tacurracy 0.97\n",
      "tensor([[ 1]])\n",
      "Train Epoch: 28 [10/40 (25%)] \tLoss; 0.011239; \tacurracy 1.00\n",
      "Train Epoch: 28 [20/40 (50%)] \tLoss; 0.027910; \tacurracy 1.00\n",
      "Train Epoch: 28 [30/40 (75%)] \tLoss; 0.000424; \tacurracy 1.00\n",
      "Train Epoch: 28 [40/40 (100%)] \tLoss; 0.000997; \tacurracy 1.00\n",
      "tensor([[ 0]])\n",
      "Train Epoch: 29 [10/40 (25%)] \tLoss; 0.000159; \tacurracy 1.00\n",
      "Train Epoch: 29 [20/40 (50%)] \tLoss; 0.003842; \tacurracy 1.00\n",
      "Train Epoch: 29 [30/40 (75%)] \tLoss; 0.008984; \tacurracy 1.00\n",
      "Train Epoch: 29 [40/40 (100%)] \tLoss; 0.000118; \tacurracy 1.00\n",
      "tensor([[ 1]])\n"
     ]
    }
   ],
   "source": [
    "def test(): \n",
    "    model.eval()\n",
    "    files = listdir('images/test/')\n",
    "    f = random.choice(files)\n",
    "    img = Image.open(\"images/test/\" + f)\n",
    "    img_eval_tensor = transform(img)\n",
    "    img_eval_tensor = img_eval_tensor.unsqueeze(0)\n",
    "    data = Variable(img_eval_tensor) #img_eval_tensor.cuda()\n",
    "    \n",
    "    out = model(data)\n",
    "    print(out.data.max(1, keepdim=True)[1])\n",
    "    img.show()\n",
    "    time.sleep(5)\n",
    "   \n",
    "    \n",
    "\n",
    "for epoch in range(1, 30):\n",
    "    train(epoch)\n",
    "    test()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
